{"cells":[{"cell_type":"markdown","source":["# Backlog"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3531475a-5527-4484-9c39-3f8046e2fb61"},{"cell_type":"markdown","source":["##### **Main Log**\n","\n","- `nb_run_logger`\n","    - notebook to run post-worker_nb run. Writes run results to audit schema. (rows read/write, noteable var values, etc)\n","- `batch_results`\n","    - notebook to write batch-level information\n","\n","##### **Maintenance**\n","\n","- clean unused imports from seeder notebooks\n","- documentation for `Dynamic Path Resolution` cells\n","\n","##### **Completed**\n","\n","**DOC: 2026.01.28**\n","\n","- `auto-scrub metadata` from ipynb files\n","    - (tool auto-removes lakehouse ids and other sensitive identifiers) \n","- `nb_seed_specs`\n","- `nb_deploy_ops_accelerator`\n","    - strip ops deployment notebook of default lakehouse(manual)\n","    - create guardrail to raise error asking user to attach default lakehouse or mount lakehouse dynamically\n","\n","**DOC: 2026.01.27**\n","\n","- `nb_seed_rest_collection`\n","    - add dynamic abfs path resolution"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7fab4414-3773-47b1-acc2-c1bf4ee276be"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}