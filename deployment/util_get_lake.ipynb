{"cells":[{"cell_type":"markdown","source":["# Get Lake\n","\n","| Parameter | Description | Use Case |\n","|---------- |-------------|----------|\n","| name | Name of the lakehouse to get/create | Always |\n","| ws_id | Target location workspace ID | Always |\n","| desc | Lakehouse description if deploying. | When deploying |\n","| schemas | Default is True | When deploying |\n","\n","\n","Purpose:\n","1. Try to get a lakehouse artifact\n","2. Deploy one if not found\n","3. Try again(in case it was a transient error)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0c8e4fd1-31a5-4900-9e2f-ead2008fe605"},{"cell_type":"code","source":["# --- PARAMETERS--- #\n","name: str = \"\"\n","ws_id: str = \"\"\n","desc: str = \"\"\n","schemas: bool = True"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"04e182aa-7070-4de2-896a-4517b19dd64a"},{"cell_type":"code","source":["# --- LAKEHOUSE GET/DEPLOY FUNCTION --- #\n","def get_or_create_lakehouse(name: str, *, workspace_id: str, description: str = \"\", enable_schemas: bool = True):\n","    try: \n","        return notebookutils.lakehouse.get(name, workspace_id) # -> get lh\n","    \n","    except Exception: \n","        definition = {\"enableSchemas\": True} if enable_schemas else None # -> with schemas enabled\n","        \n","        try:\n","            return notebookutils.lakehouse.create(name, description, definition, workspace_id) # -> create with definition\n","        \n","        except Exception: # -> in case was transient\n","            return notebookutils.lakehouse.get(name, workspace_id) # -> get lh"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"91c8d29c-3ee6-43cc-bd1b-fffdba3afecd"},{"cell_type":"code","source":["# --- EXECUTION --- #\n","lake = get_or_create_lakehouse(\n","    name=name,\n","    workspace_id=ws_id,\n","    description=desc,\n","    enable_schemas=schemas\n","    )"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a7567df3-40ac-408c-929c-823a65f2c8d5"},{"cell_type":"code","source":["# --- EXIT --- #\n","import json\n","notebookutils.notebook.exit(json.dumps(lake))"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"90a8e8ed-c420-476d-a7a6-b1bae24414ff"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}